"""
AI-Generated Content Detection Module

This module provides functionality to analyze images and estimate the probability
that they were generated by AI systems.

Note: This is an MVP implementation focusing on image analysis using statistical
and heuristic approaches. For production use, consider integrating trained ML models.
"""

import numpy as np
from PIL import Image
from PIL.ExifTags import TAGS
import io


class ImageDetector:
    """
    Analyzes images to determine the probability of AI generation.
    
    This detector uses multiple heuristics:
    - EXIF metadata analysis
    - Compression artifact patterns
    - Color distribution analysis
    - Image statistics
    """
    
    def __init__(self):
        self.confidence_threshold = 0.6
        
    def analyze_image(self, image_data):
        """
        Analyze an image and return probability of AI generation.
        
        Args:
            image_data: Binary image data or PIL Image object
            
        Returns:
            dict: {
                'probability': float (0-1),
                'confidence': str ('low', 'medium', 'high'),
                'factors': dict of contributing factors
            }
        """
        # Open image if binary data provided
        if isinstance(image_data, bytes):
            image = Image.open(io.BytesIO(image_data))
        else:
            image = image_data
            
        # Run analysis
        factors = {}
        
        # Check EXIF metadata
        exif_score = self._analyze_exif(image)
        factors['exif_analysis'] = exif_score
        
        # Analyze compression artifacts
        compression_score = self._analyze_compression(image)
        factors['compression_artifacts'] = compression_score
        
        # Color distribution analysis
        color_score = self._analyze_color_distribution(image)
        factors['color_distribution'] = color_score
        
        # Statistical analysis
        stats_score = self._analyze_statistics(image)
        factors['statistical_patterns'] = stats_score
        
        # Calculate weighted probability
        weights = {
            'exif_analysis': 0.3,
            'compression_artifacts': 0.25,
            'color_distribution': 0.25,
            'statistical_patterns': 0.2
        }
        
        probability = sum(factors[key] * weights[key] for key in weights.keys())
        
        # Determine confidence level
        confidence = self._calculate_confidence(factors)
        
        return {
            'probability': round(probability, 3),
            'confidence': confidence,
            'factors': factors,
            'disclaimer': self._get_disclaimer()
        }
    
    def _analyze_exif(self, image):
        """
        Analyze EXIF metadata for signs of AI generation.
        Missing or suspicious metadata can indicate AI generation.
        """
        try:
            exif_data = image._getexif()
            
            if exif_data is None:
                # No EXIF data is suspicious
                return 0.7
            
            # Check for camera information
            has_camera_info = False
            has_software_info = False
            
            for tag_id, value in exif_data.items():
                tag = TAGS.get(tag_id, tag_id)
                if tag in ['Make', 'Model']:
                    has_camera_info = True
                if tag == 'Software':
                    has_software_info = True
                    # Check for AI generation software keywords
                    if any(keyword in str(value).lower() for keyword in 
                           ['midjourney', 'dall-e', 'stable diffusion', 'ai', 'generated']):
                        return 0.9
            
            if has_camera_info:
                return 0.2  # Likely real camera
            elif not has_software_info:
                return 0.6  # Suspicious lack of metadata
            else:
                return 0.5  # Neutral
                
        except (AttributeError, KeyError):
            return 0.6  # No EXIF data available
    
    def _analyze_compression(self, image):
        """
        Analyze compression artifacts.
        AI-generated images often have unusual compression patterns.
        """
        # Convert to RGB if necessary
        if image.mode != 'RGB':
            image = image.convert('RGB')
        
        img_array = np.array(image)
        
        # Calculate local variance to detect compression artifacts
        if img_array.shape[0] > 100 and img_array.shape[1] > 100:
            # Sample a region
            region = img_array[50:150, 50:150, :]
            variance = np.var(region)
            
            # Very low variance can indicate AI smoothing
            if variance < 100:
                return 0.7
            elif variance > 2000:
                return 0.3
            else:
                return 0.5
        
        return 0.5
    
    def _analyze_color_distribution(self, image):
        """
        Analyze color distribution patterns.
        AI-generated images often have characteristic color distributions.
        """
        if image.mode != 'RGB':
            image = image.convert('RGB')
        
        img_array = np.array(image)
        
        # Calculate color channel statistics
        r_channel = img_array[:, :, 0].flatten()
        g_channel = img_array[:, :, 1].flatten()
        b_channel = img_array[:, :, 2].flatten()
        
        # Check for unnaturally uniform distributions
        r_std = np.std(r_channel)
        g_std = np.std(g_channel)
        b_std = np.std(b_channel)
        
        avg_std = (r_std + g_std + b_std) / 3
        
        # Very uniform colors can indicate AI generation
        if avg_std < 30:
            return 0.8
        elif avg_std > 80:
            return 0.3
        else:
            # Check channel correlation (AI images often have high correlation)
            correlation = np.corrcoef([r_channel[:1000], g_channel[:1000], b_channel[:1000]])
            avg_corr = (correlation[0, 1] + correlation[0, 2] + correlation[1, 2]) / 3
            
            if avg_corr > 0.9:
                return 0.7
            else:
                return 0.4
    
    def _analyze_statistics(self, image):
        """
        Analyze statistical properties of the image.
        """
        if image.mode != 'RGB':
            image = image.convert('RGB')
        
        img_array = np.array(image)
        
        # Check image dimensions (AI often generates at specific resolutions)
        width, height = image.size
        common_ai_sizes = [512, 768, 1024, 2048]
        
        if width in common_ai_sizes and height in common_ai_sizes:
            return 0.7
        elif width == height:  # Square images common in AI generation
            return 0.6
        else:
            return 0.4
    
    def _calculate_confidence(self, factors):
        """
        Calculate confidence level based on factor agreement.
        """
        values = list(factors.values())
        std_dev = np.std(values)
        
        # If factors agree (low std dev), confidence is higher
        if std_dev < 0.15:
            return 'high'
        elif std_dev < 0.25:
            return 'medium'
        else:
            return 'low'
    
    def _get_disclaimer(self):
        """
        Return standard disclaimer about AI detection.
        """
        return ("This analysis provides an estimate based on technical characteristics "
                "and should not be considered definitive proof. AI detection technology "
                "is continuously evolving, and this tool may produce false positives or "
                "false negatives. Use results as guidance only, not as absolute truth.")
